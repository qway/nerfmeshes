# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  id: nerf-synthetic-lego
  # Base model, whether to use tree voxel sampling (BuFFModel) instead of hierarchical sampling (NeRFModel)
  model: NeRFModel
  # Experiment description
  description: High res lego nerf model.
  # Experiment logs will be stored at "logdir"/"id"
  logdir: ../logs
  # Seed for random number generators (for repeatability).
  randomseed: 42
  # Number of training iterations.
  train_iters: 250000
  # Number of training iterations after which to validate.
  validate_every: 5000
  # Number of training iterations after which to print progress.
  print_every: 100
  # Base directory of mesh dataset.
  meshdir: ../data/meshes
  # Training early stopping due to being stuck in local minima
  use_early_stopping: False
  # Early stopping step
  early_stopping_step: 25
  # Compute chamfer loss
  chamfer_loss: False
  # Chamfer loss sampling size
  chamfer_sampling_size: 2400

# Logging parameters
logging:
  # Use acronyms for compact logging
  use_acronyms: True
  # Project 2D points into synthetic world space
  use_projection: True
  # Step size for use_projection
  projection_step_size: 5000

# Dataset parameters.
dataset:
  # Type of dataset (Blender vs LLFF vs DeepVoxels vs something else)
  type: blender
  # Path to the root dir of the chosen dataset.
  basedir: ../data/nerf_synthetic/lego
  # For the Blender dataset (synthetic), implies resolution scale
  reduced_resolution: 1
  # Stride (include one per "testskip" images in the dataset). Stride length (Blender datasets only).
  # When set to k (k > 1), it samples every kth sample from the dataset.
  testskip: 1
  # Use NDC (normalized device coordinates). Usually True for synthetic (Blender) datasets.
  use_ndc: False
  # Near clip plane (clip all depth values closer than this threshold).
  near: 2
  # Far clip plane (clip all depth values farther than this threshold).
  far: 6
  # Depth empty space plane.
  empty: 0.
  # Num workers.
  num_workers: 6
  # Down-sample factor for images from the LLFF dataset.
  llff_downsample_factor: 8
  # Determines the hold-out images for LLFF.
  llff_hold_step: 8
  # Whether to render models using a white background (only for synthetic datasets).
  white_background: False
  # Caching parameters (works only on Blender, LLFF).
  caching:
    # Use cached dataset, if it's not created, create one.
    use_caching: False
    # Override existing cached dataset when new changes are done to the dataset loader.
    override_caching: False
    # Overrides basedir path to the following pre-cached dataset dir.
    cache_dir: ../cache/syn-lego-cache
    # Number of random ray batches to draw per image as infinite data can't be cached.
    num_variations: 4
    # Sample all rays for the image and perform ray-batching during runtime.
    # Overrides --num-random-rays and num_variations.
    sample_all: True

# Model parameters.
models:
  # Coarse model.
  # Name of the torch.nn.Module class that implements the model.
  coarse_type: FlexibleNeRFModel
  # Coarse model parameters.
  coarse:
    # Number of layers in the model.
    num_layers: 8
    # Add a skip connection once in a while.
    skip_step: 4
    # Position encoding.
    encoding: positional
    # Number of view dependent layers (-1 for no view dependence)
    num_layers_view: -1
    # Size of the hidden layers
    hidden_size: 256
    # Whether to include the position (xyz) itself in its positional
    # encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding
    # of the coordinates.
    log_sampling_xyz: True
    # Number of encoding functions to use in the positional encoding
    # of the coordinates.
    num_encoding_fn_xyz: 10
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: True
    # Number of encoding functions to use in the positional encoding
    # of the direction.
    num_encoding_fn_dir: 4
    # Whether or not to perform log sampling in the positional encoding
    # of the direction.
    log_sampling_dir: True
    # Additionally use viewing directions as input.
    use_viewdirs: True

  # Fine model.
  # Name of the torch.nn.Module class that implements the model.
  fine_type: FlexibleNeRFModel
  # Whether to use the final model.
  use_fine: True
  # Fine model parameters.
  fine:
    # Number of layers in the model.
    num_layers: 8
    # Add a skip connection once in a while.
    skip_step: 4
    # Position encoding.
    encoding: positional
    # Number of view dependent layers(-1 for no view dependence)
    num_layers_view: -1
    # Size of the hidden layers
    hidden_size: 256
    # Whether to include the position (xyz) itself in its positional
    # encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding
    # of the coordinates.
    log_sampling_xyz: True
    # Number of encoding functions to use in the positional encoding
    # of the coordinates.
    num_encoding_fn_xyz: 10
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: True
    # Number of encoding functions to use in the positional encoding of the direction.
    num_encoding_fn_dir: 4
    # Whether or not to perform log sampling in the positional encoding of the direction.
    log_sampling_dir: True
    # Additionally use viewing directions as input.
    use_viewdirs: True

# Optimizer params.
optimizer:
  # Name of the torch.optim class used for optimization.
  type: Adam
  # Learning rate. Default 5.0E-3
  lr: 5.0E-3

# Learning rate scheduler.
scheduler:
  # Scheduler type, either use custom DefaultScheduler or any from torch.optim.lr_scheduler
  type: DefaultScheduler
  # Scheduler params
  options:
    # Multiplicative factor of learning rate decay.
    gamma: 0.1
    # Period of learning rate decay. train_iters * 180%
    step_size: 450000

# NeRF parameters.
nerf:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # Encoding function for position (X, Y, Z).
  encode_position_fn: positional_encoding
  # Encoding function for ray direction (theta, phi).
  encode_direction_fn: positional_encoding
  # Training-specific parameters.
  train:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    num_random_rays: 2048
    # Size of each chunk (rays are batched into "chunks" and passed through
    # the network)
    chunksize: 2048
    # Whether or not to perturb the sampled depth values.
    perturb: False
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 128
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.2
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
  # Validation-specific parameters.
  validation:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    chunksize: 2048
    # Whether or not to perturb the sampled depth values.
    perturb: False
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 128
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
    # Use smaller pool of random batch samples for faster validation epoch, use -1 if use the whole dataset.
    num_samples: 1
